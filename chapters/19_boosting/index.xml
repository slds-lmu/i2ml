<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Chapter 19: Boosting on Introduction to Machine Learning (I2ML)</title><link>https://slds-lmu.github.io/i2ml/chapters/19_boosting/</link><description>Recent content in Chapter 19: Boosting on Introduction to Machine Learning (I2ML)</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://slds-lmu.github.io/i2ml/chapters/19_boosting/index.xml" rel="self" type="application/rss+xml"/><item><title>Chapter 20.01: Introduction to Boosting / AdaBoost</title><link>https://slds-lmu.github.io/i2ml/chapters/19_boosting/19-01-intro-adaboost/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://slds-lmu.github.io/i2ml/chapters/19_boosting/19-01-intro-adaboost/</guid><description>&lt;p>In this section, we introduce the pioneering AdaBoost algorithm.&lt;/p></description></item><item><title>Chapter 20.02: Boosting Concept</title><link>https://slds-lmu.github.io/i2ml/chapters/19_boosting/19-02-gradient-boosting-concept/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://slds-lmu.github.io/i2ml/chapters/19_boosting/19-02-gradient-boosting-concept/</guid><description>&lt;p>In this section, we discuss the general boosting principle: performing gradient descent in function space by repeatedly fitting new base learner components to the current pseudo-residuals.&lt;/p></description></item><item><title>Chapter 20.03: Boosting Illustration</title><link>https://slds-lmu.github.io/i2ml/chapters/19_boosting/19-03-gradient-boosting-illustration/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://slds-lmu.github.io/i2ml/chapters/19_boosting/19-03-gradient-boosting-illustration/</guid><description>&lt;p>We show several illustrative regression examples to visualize the boosting
principle.&lt;/p></description></item><item><title>Chapter 20.04: Boosting Regularization</title><link>https://slds-lmu.github.io/i2ml/chapters/19_boosting/19-04-gradient-boosting-regularization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://slds-lmu.github.io/i2ml/chapters/19_boosting/19-04-gradient-boosting-regularization/</guid><description>&lt;p>Powerful boosting learners tend to overfit. We discuss the number of iterations, base learner complexity, and shrinkage as countermeasures.&lt;/p></description></item><item><title>Chapter 20.05: Boosting for Classification</title><link>https://slds-lmu.github.io/i2ml/chapters/19_boosting/19-05-gradient-boosting-classification/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://slds-lmu.github.io/i2ml/chapters/19_boosting/19-05-gradient-boosting-classification/</guid><description>&lt;p>We introduce boosting algorithms for both binary and multiclass classification with several examples.&lt;/p></description></item><item><title>Chapter 20.06: Gradient Boosting with Trees I</title><link>https://slds-lmu.github.io/i2ml/chapters/19_boosting/19-06-gradient-boosting-trees-1/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://slds-lmu.github.io/i2ml/chapters/19_boosting/19-06-gradient-boosting-trees-1/</guid><description>&lt;p>We discuss trees as the most popular base learners in gradient boosting, with special emphasis on model structure and interaction depth.&lt;/p></description></item><item><title>Chapter 20.07: Gradient Boosting with Trees II</title><link>https://slds-lmu.github.io/i2ml/chapters/19_boosting/19-07-gradient-boosting-trees-2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://slds-lmu.github.io/i2ml/chapters/19_boosting/19-07-gradient-boosting-trees-2/</guid><description>&lt;p>We explain how terminal coefficients are found in a risk-minimal manner and briefly discuss tree-based boosting for multiclass problems.&lt;/p></description></item><item><title>Chapter 20.08: XGBoost</title><link>https://slds-lmu.github.io/i2ml/chapters/19_boosting/19-08-gradient-boosting-xgboost/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://slds-lmu.github.io/i2ml/chapters/19_boosting/19-08-gradient-boosting-xgboost/</guid><description>&lt;p>We introduce XGBoost, a highly efficient, tree-based boosting system with additional regularizers.&lt;/p></description></item></channel></rss>